{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Bản sao của Project DS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Dfjh-x07l2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T075NRYbqvZ1"
      },
      "source": [
        "!pip uninstall imgaug -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIFklXrgto4T"
      },
      "source": [
        "!pip install git+https://github.com/aleju/imgaug.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf3Zgjr6nex-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341b78df-90cf-4097-c63c-e72e7a53dcb5"
      },
      "source": [
        "%cd /content/drive/MyDrive/DataScience/plate_project_group09"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Vt0fOz_0sVJoPLSXwaaNYYz64X3oIxL9/DataScience/plate_project_group09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8IsUzOAr-As"
      },
      "source": [
        "!cd /content/plate_detector/ && unzip '/content/drive/MyDrive/DataScience/plate_project_group09/datasets/plate1.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INsbFtJlolNV"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from utils import decode_netout\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "from losses import YoloLoss\n",
        "from callbacks import MapEvaluation\n",
        "from data_generator import BatchGenerator, parse_annotation_xml\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "root = \"/content/drive/MyDrive/DataScience/plate_project_group09/\"\n",
        "\n",
        "class PlateDetector:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.anchors = [0.79158,0.99434, 1.22290,1.60963, 1.75330,2.34127, 2.40385,1.27696, 2.60130,3.37916]\n",
        "        self.num_anchors = len(self.anchors)//2\n",
        "        self.labels = ['license plates']\n",
        "        self.num_classes = len(self.labels)\n",
        "        self.batch_size = 16\n",
        "\n",
        "    def build_model(self):\n",
        "        \n",
        "        backend = InceptionV3(\n",
        "            include_top = False,\n",
        "            input_shape = [500, 500, 3],\n",
        "            weights = root + 'pretrained/inception_backend.h5'\n",
        "        )\n",
        "        \n",
        "        conv_layer_1 = Conv2D(filters = self.num_anchors * (5 + self.num_classes), kernel_size = [1, 1])(backend.output)\n",
        "        output_layer = Reshape([14, 14, self.num_anchors, 6])(conv_layer_1)\n",
        "\n",
        "\n",
        "        self.model = Model(backend.input, output_layer)\n",
        "        self.model.summary()\n",
        "        \n",
        "        self.loss = YoloLoss(\n",
        "            self.anchors,\n",
        "            [14, 14],\n",
        "            self.batch_size,\n",
        "            lambda_obj = 5\n",
        "        )\n",
        "        \n",
        "        self.optimizer = Adam(learning_rate = 1e-4, epsilon=1e-8, decay=0.0)\n",
        "        run_opts = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)\n",
        "        self.model.compile(loss = self.loss, optimizer = self.optimizer)\n",
        "        \n",
        "        \n",
        "\n",
        "    def save_model(self):\n",
        "        pass  # delete this line and replace yours\n",
        "\n",
        "    def load_model(self):\n",
        "        pass  # delete this line and replace yours\n",
        "\n",
        "    def train(self, **kwargs):\n",
        "        num_anchors = len(self.anchors)//2\n",
        "        list_train_images, _ = parse_annotation_xml(\n",
        "                        '/content/plate_detector/train/anns',\n",
        "                        '/content/plate_detector/train/images'\n",
        "        )\n",
        "        \n",
        "        list_valid_images, _ = parse_annotation_xml(\n",
        "                        '/content/plate_detector/valid/anns',\n",
        "                        '/content/plate_detector/valid/images'\n",
        "        )\n",
        "        \n",
        "        generator_config = {\n",
        "             'IMAGE_H' : 500,\n",
        "             'IMAGE_W' : 500,\n",
        "             'IMAGE_C' : 3,\n",
        "             'GRID_H'  : 14,\n",
        "             'GRID_W'  : 14,\n",
        "             'BOX'     : self.num_anchors,\n",
        "             'LABELS'  : self.labels,\n",
        "             'CLASS'   : self.num_classes,\n",
        "             'ANCHORS' : self.anchors,\n",
        "             'BATCH_SIZE' : self.batch_size\n",
        "        }\n",
        "        \n",
        "        valid_generator = BatchGenerator(\n",
        "            list_valid_images, generator_config, preprocess_input = preprocess_input\n",
        "        )\n",
        "        train_generator = BatchGenerator(\n",
        "            list_train_images, generator_config, preprocess_input = preprocess_input\n",
        "        )\n",
        "    \n",
        "        map_evaluation = MapEvaluation(\n",
        "            self, valid_generator,\n",
        "            iou_threshold = 0.6,\n",
        "            save_best = True,\n",
        "            save_name = root + 'models/plate_best.hdf5'\n",
        "        )\n",
        "        \n",
        "        self.model.fit_generator(\n",
        "            train_generator,\n",
        "            steps_per_epoch = int(len(train_generator) * 0.1),\n",
        "            epochs = 100,\n",
        "            validation_data = valid_generator,\n",
        "            validation_steps = int(len(valid_generator) * 0.1),\n",
        "            callbacks = [map_evaluation]\n",
        "        )\n",
        "\n",
        "    def predict(self, image):\n",
        "        \"\"\"\n",
        "        Autotest will call this function\n",
        "        :param image: a PIL Image object\n",
        "        :return: a list of boxes, each item is a tuple of (x_min, y_min, x_max, y_max)\n",
        "        \"\"\"\n",
        "        w = image.width\n",
        "        h = image.height\n",
        "        image = image.resize([500, 500])\n",
        "        image_np = np.array(image)\n",
        "        preprocessed_image = np.array([self.preprocess_input(image_np)])\n",
        "        netout = self.model.predict(preprocessed_image)[0]\n",
        "        boxes = decode_netout(\n",
        "            netout, self.anchors, self.num_classes, 0.5, 0.5\n",
        "        )\n",
        "        list_result = []\n",
        "        for box in boxes:\n",
        "            xmin = box.xmin * w\n",
        "            ymin = box.ymin * h\n",
        "            xmax = box.xmax * w\n",
        "            ymax = box.ymax * h\n",
        "            list_result.append((xmin, ymin, xmax, ymax))\n",
        "        return list_result\n",
        "\n",
        "    def preprocess_input(self, image):\n",
        "        return preprocess_input(image)\n",
        "\n",
        "    def infer(self, image, iou_threshold=0.5, score_threshold=0.5):\n",
        "        image = cv2.resize(image, (500, 500))\n",
        "        image = image[..., ::-1]  # make it RGB (it is important for normalization of some backends)\n",
        "\n",
        "        image = self.preprocess_input(image)\n",
        "        if len(image.shape) == 3:\n",
        "            input_image = image[np.newaxis, :]\n",
        "        else:\n",
        "            input_image = image[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        netout = self.model.predict(input_image)[0]\n",
        "\n",
        "        boxes = decode_netout(netout, self.anchors, self.num_classes, score_threshold, iou_threshold)\n",
        "\n",
        "        return boxes\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z4eHzxMuAoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9025b9a-9055-4010-b3c6-f008489f3967"
      },
      "source": [
        "detector = PlateDetector()\n",
        "detector.build_model()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 500, 500, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 249, 249, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 249, 249, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 249, 249, 32) 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 247, 247, 32) 9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 247, 247, 32) 96          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 247, 247, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 247, 247, 64) 18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 247, 247, 64) 192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 247, 247, 64) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 123, 123, 64) 0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 123, 123, 80) 5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 123, 123, 80) 240         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 123, 123, 80) 0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 121, 121, 192 138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 121, 121, 192 576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 121, 121, 192 0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 60, 60, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 60, 60, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 60, 60, 64)   192         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 60, 60, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 60, 60, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 60, 60, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 60, 60, 48)   144         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 60, 60, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 60, 60, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 60, 60, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 60, 60, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 60, 60, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 60, 60, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 60, 60, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 60, 60, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 60, 60, 64)   192         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 60, 60, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 60, 60, 96)   288         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 60, 60, 32)   96          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 60, 60, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 60, 60, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 60, 60, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 60, 60, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 60, 60, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 60, 60, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 60, 60, 64)   192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 60, 60, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 60, 60, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 60, 60, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 60, 60, 48)   144         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 60, 60, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 60, 60, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 60, 60, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 60, 60, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 60, 60, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 60, 60, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 60, 60, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 60, 60, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 60, 60, 64)   192         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 60, 60, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 60, 60, 96)   288         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 60, 60, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 60, 60, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 60, 60, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 60, 60, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 60, 60, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 60, 60, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 60, 60, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 60, 60, 64)   192         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 60, 60, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 60, 60, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 60, 60, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 60, 60, 48)   144         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 60, 60, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 60, 60, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 60, 60, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 60, 60, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 60, 60, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 60, 60, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 60, 60, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 60, 60, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 60, 60, 64)   192         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 60, 60, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 60, 60, 96)   288         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 60, 60, 64)   192         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 60, 60, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 60, 60, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 60, 60, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 60, 60, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 60, 60, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 60, 60, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 60, 60, 64)   192         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 60, 60, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 60, 60, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 60, 60, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 60, 60, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 29, 29, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 29, 29, 96)   82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 29, 29, 384)  1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 29, 29, 96)   288         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 29, 29, 384)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 29, 29, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 29, 29, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 29, 29, 768)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 29, 29, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 29, 29, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 29, 29, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 29, 29, 128)  114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 29, 29, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 29, 29, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 29, 29, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 29, 29, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 29, 29, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 29, 29, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 29, 29, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 29, 29, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 29, 29, 128)  114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 29, 29, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 29, 29, 128)  384         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 29, 29, 128)  384         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 29, 29, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 29, 29, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 29, 29, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 29, 29, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 29, 29, 192)  172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 29, 29, 192)  172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 29, 29, 192)  147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 29, 29, 192)  576         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 29, 29, 192)  576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 29, 29, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 29, 29, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 29, 29, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 29, 29, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 29, 29, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 29, 29, 192)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 29, 29, 768)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 29, 29, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 29, 29, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 29, 29, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 29, 29, 160)  179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 29, 29, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 29, 29, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 29, 29, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 29, 29, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 29, 29, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 29, 29, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 29, 29, 160)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 29, 29, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 29, 29, 160)  179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 29, 29, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 29, 29, 160)  480         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 29, 29, 160)  480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 29, 29, 160)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 29, 29, 160)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 29, 29, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 29, 29, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 29, 29, 192)  215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 29, 29, 192)  215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 29, 29, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 29, 29, 192)  576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 29, 29, 192)  576         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 29, 29, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 29, 29, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 29, 29, 192)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 29, 29, 192)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 29, 29, 192)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 29, 29, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 29, 29, 768)  0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 29, 29, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 29, 29, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 29, 29, 160)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 29, 29, 160)  179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 29, 29, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 29, 29, 160)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 29, 29, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 29, 29, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 29, 29, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 29, 29, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 29, 29, 160)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 29, 29, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 29, 29, 160)  179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 29, 29, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 29, 29, 160)  480         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 29, 29, 160)  480         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 29, 29, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 29, 29, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 29, 29, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 29, 29, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 29, 29, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 29, 29, 192)  215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 29, 29, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 29, 29, 192)  576         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 29, 29, 192)  576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 29, 29, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 29, 29, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 29, 29, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 29, 29, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 29, 29, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 29, 29, 192)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 29, 29, 768)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 29, 29, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 29, 29, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 29, 29, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 29, 29, 192)  258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 29, 29, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 29, 29, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 29, 29, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 29, 29, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 29, 29, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 29, 29, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 29, 29, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 29, 29, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 29, 29, 192)  258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 29, 29, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 29, 29, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 29, 29, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 29, 29, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 29, 29, 192)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 29, 29, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 29, 29, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 29, 29, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 29, 29, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 29, 29, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 29, 29, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 29, 29, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 29, 29, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 29, 29, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 29, 29, 192)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 29, 29, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 29, 29, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 29, 29, 192)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 29, 29, 768)  0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 29, 29, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 29, 29, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 29, 29, 192)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 29, 29, 192)  258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 29, 29, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 29, 29, 192)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 29, 29, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 29, 29, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 29, 29, 192)  576         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 29, 29, 192)  576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 29, 29, 192)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 29, 29, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 14, 14, 320)  552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 14, 14, 192)  331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 14, 14, 320)  960         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 14, 14, 192)  576         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 14, 14, 320)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 14, 14, 192)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 14, 14, 768)  0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 14, 14, 1280) 0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 14, 14, 448)  573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 14, 14, 448)  1344        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 14, 14, 448)  0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 14, 14, 384)  491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 14, 14, 384)  1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 14, 14, 384)  1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 14, 14, 384)  1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 14, 14, 384)  0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 14, 14, 384)  0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 14, 14, 384)  442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 14, 14, 384)  442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 14, 14, 384)  442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 14, 14, 384)  442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 14, 14, 1280) 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 14, 14, 320)  409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 14, 14, 384)  1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 14, 14, 384)  1152        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 14, 14, 384)  1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 14, 14, 384)  1152        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 14, 14, 192)  245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 14, 14, 320)  960         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 14, 14, 384)  0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 14, 14, 384)  0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 14, 14, 384)  0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 14, 14, 384)  0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 14, 14, 192)  576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 14, 14, 320)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 14, 14, 768)  0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 14, 14, 192)  0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 14, 14, 2048) 0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 14, 14, 448)  917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 14, 14, 448)  1344        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 14, 14, 448)  0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 14, 14, 384)  786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 14, 14, 384)  1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 14, 14, 384)  1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 14, 14, 384)  1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 14, 14, 384)  0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 14, 14, 384)  0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 14, 14, 384)  442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 14, 14, 384)  442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 14, 14, 384)  442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 14, 14, 384)  442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 14, 14, 2048) 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 14, 14, 320)  655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 14, 14, 384)  1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 14, 14, 384)  1152        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 14, 14, 384)  1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 14, 14, 384)  1152        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 14, 14, 192)  393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 14, 14, 320)  960         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 14, 14, 384)  0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 14, 14, 384)  0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 14, 14, 384)  0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 14, 14, 384)  0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 14, 14, 192)  576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 14, 14, 320)  0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 14, 14, 768)  0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 14, 14, 768)  0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 14, 14, 192)  0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 14, 14, 2048) 0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 14, 14, 30)   61470       mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 14, 14, 5, 6) 0           conv2d_189[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 21,864,254\n",
            "Trainable params: 21,829,822\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XBC6n1hGyyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195fb154-cff5-4d4a-8a31-0bbed0630d5f"
      },
      "source": [
        "detector.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/imgaug/imgaug.py:188: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
            "  warn_deprecated(msg, stacklevel=3)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 29s 3s/step - loss: 1461.1873\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 748.6797\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 383.8662\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 20s 3s/step - loss: 214.6025\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 142.0446\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 106.3160\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 101.2938\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 17s 2s/step - loss: 78.5349\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 17s 2s/step - loss: 67.3118\n",
            "\n",
            "\n",
            "license plates 0.0009\n",
            "mAP: 0.0009\n",
            "mAP improved from 0 to 0.0008818342151675485, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 63.6433\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0008818342151675485.\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 59.9512\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0008818342151675485.\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 55.1266\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0008818342151675485.\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 52.7517\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0008818342151675485.\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 50.1041\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0008818342151675485.\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 44.4117\n",
            "\n",
            "\n",
            "license plates 0.0006\n",
            "mAP: 0.0006\n",
            "mAP did not improve from 0.0008818342151675485.\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 51.6028\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0008818342151675485.\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 41.1469\n",
            "\n",
            "\n",
            "license plates 0.0021\n",
            "mAP: 0.0021\n",
            "mAP improved from 0.0008818342151675485 to 0.0020576131687242796, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 42.4166\n",
            "\n",
            "\n",
            "license plates 0.0005\n",
            "mAP: 0.0005\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 42.0920\n",
            "\n",
            "\n",
            "license plates 0.0005\n",
            "mAP: 0.0005\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 36.7127\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 45.1418\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 16s 2s/step - loss: 37.1367\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 35.1838\n",
            "\n",
            "\n",
            "license plates 0.0007\n",
            "mAP: 0.0007\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 36.3751\n",
            "\n",
            "\n",
            "license plates 0.0002\n",
            "mAP: 0.0002\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 38.0476\n",
            "\n",
            "\n",
            "license plates 0.0017\n",
            "mAP: 0.0017\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 30.5530\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 35.7523\n",
            "\n",
            "\n",
            "license plates 0.0002\n",
            "mAP: 0.0002\n",
            "mAP did not improve from 0.0020576131687242796.\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 33.0175\n",
            "\n",
            "\n",
            "license plates 0.0025\n",
            "mAP: 0.0025\n",
            "mAP improved from 0.0020576131687242796 to 0.0024882763900851753, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 31.5080\n",
            "\n",
            "\n",
            "license plates 0.0031\n",
            "mAP: 0.0031\n",
            "mAP improved from 0.0024882763900851753 to 0.0030555555555555553, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 28.5365\n",
            "\n",
            "\n",
            "license plates 0.0113\n",
            "mAP: 0.0113\n",
            "mAP improved from 0.0030555555555555553 to 0.01127996835828161, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 28.4075\n",
            "\n",
            "\n",
            "license plates 0.0023\n",
            "mAP: 0.0023\n",
            "mAP did not improve from 0.01127996835828161.\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 27.8436\n",
            "\n",
            "\n",
            "license plates 0.0060\n",
            "mAP: 0.0060\n",
            "mAP did not improve from 0.01127996835828161.\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 28.5251\n",
            "\n",
            "\n",
            "license plates 0.0045\n",
            "mAP: 0.0045\n",
            "mAP did not improve from 0.01127996835828161.\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 25.1018\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.01127996835828161.\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 31.4234\n",
            "\n",
            "\n",
            "license plates 0.0078\n",
            "mAP: 0.0078\n",
            "mAP did not improve from 0.01127996835828161.\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 27.8152\n",
            "\n",
            "\n",
            "license plates 0.0000\n",
            "mAP: 0.0000\n",
            "mAP did not improve from 0.01127996835828161.\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 25.1334\n",
            "\n",
            "\n",
            "license plates 0.0070\n",
            "mAP: 0.0070\n",
            "mAP did not improve from 0.01127996835828161.\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 17s 2s/step - loss: 26.2479\n",
            "\n",
            "\n",
            "license plates 0.0116\n",
            "mAP: 0.0116\n",
            "mAP improved from 0.01127996835828161 to 0.011572620957429494, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 20.0477\n",
            "\n",
            "\n",
            "license plates 0.0225\n",
            "mAP: 0.0225\n",
            "mAP improved from 0.011572620957429494 to 0.022480382383764028, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 22.3854\n",
            "\n",
            "\n",
            "license plates 0.0265\n",
            "mAP: 0.0265\n",
            "mAP improved from 0.022480382383764028 to 0.026538113621016955, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 23.3362\n",
            "\n",
            "\n",
            "license plates 0.0328\n",
            "mAP: 0.0328\n",
            "mAP improved from 0.026538113621016955 to 0.03283611341968014, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 28.5997\n",
            "\n",
            "\n",
            "license plates 0.0289\n",
            "mAP: 0.0289\n",
            "mAP did not improve from 0.03283611341968014.\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 24.0168\n",
            "\n",
            "\n",
            "license plates 0.0358\n",
            "mAP: 0.0358\n",
            "mAP improved from 0.03283611341968014 to 0.03576380147215315, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 22.4146\n",
            "\n",
            "\n",
            "license plates 0.0199\n",
            "mAP: 0.0199\n",
            "mAP did not improve from 0.03576380147215315.\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 19s 2s/step - loss: 22.1101\n",
            "\n",
            "\n",
            "license plates 0.0202\n",
            "mAP: 0.0202\n",
            "mAP did not improve from 0.03576380147215315.\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 20.1271\n",
            "\n",
            "\n",
            "license plates 0.0230\n",
            "mAP: 0.0230\n",
            "mAP did not improve from 0.03576380147215315.\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 17s 2s/step - loss: 24.0617\n",
            "\n",
            "\n",
            "license plates 0.0238\n",
            "mAP: 0.0238\n",
            "mAP did not improve from 0.03576380147215315.\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 18s 2s/step - loss: 20.4381\n",
            "\n",
            "\n",
            "license plates 0.0419\n",
            "mAP: 0.0419\n",
            "mAP improved from 0.03576380147215315 to 0.04185496857306114, saving model to /content/drive/MyDrive/DataScience/plate_project_group09/models/plate_best.hdf5.\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 20s 2s/step - loss: 23.4079\n",
            "\n",
            "\n",
            "license plates 0.0206\n",
            "mAP: 0.0206\n",
            "mAP did not improve from 0.04185496857306114.\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 16s 2s/step - loss: 17.8098\n",
            "\n",
            "\n",
            "license plates 0.0302\n",
            "mAP: 0.0302\n",
            "mAP did not improve from 0.04185496857306114.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDX8hFiK_D8l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}